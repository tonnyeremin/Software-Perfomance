# Прикладной Data-Science. Анализируем Производительность Приложения. 

## 1. Вступление

В крупной этерпрайз среде, производительность приложений выходит на первый план, в особенности, если мы говорим о критически важных приложениях с циклом работы 24/7/365. Имеено к такому типу относится продукт Veeam Backup & Replication. Решение компaнии Veeam предназначено для резервного копирования и восстановления физических и виртуальных машин. В продукте использована клиет-серверная архитектура. В роли фронтенда выступают, классические windows приложения, Power Shell, веб интерфейс. Бэкенд представляет из себя набор из более чем десятка windows сервисов, обеспечивающих как работу фронтенда так и интеграцию с инфраструктурой: Vmware, Hyper-V, Cloud, Tapes, агенты на физических машинах итд. 

Анализ производительности больших приложений является широкой областью и включает в себя большой набор методологий и инструментов. На данный момент на рынке существует большое колличество решений, которые позволяют рассматривать произврдительность прилодения по разными углами, снимать различные метрики, анализировать работу под нагрузкой, измерять откли пользовательского интерфейса и.т.п.  Однако, существует большой класс задач, которые сложно рещить  стандартными средствами. К примеру, к таким задачам относится глубинный анализ производительности а также логики работы отдельных компонентов приложения на больших итервалах времени.

Рассмотрим для примера механизм кэширования данных. В нашем случае механизм кэширование используется для снижения нагрузки на базу данных сокращению колличетсва однотипных запросов от клиентов, а также для уменьшения объема передаваемых данных по сети. Алгоритм работы реализован следующим образом: 

1. Первый (запрос имеющий метку 0) предстваления инициирует создание кэша для этого предстваления. 
2. В ответ кэш полуает полный набор данных и возвращает их клиенту. 
3. Включается механизм обновления кэша. С некоторой переодичностью кэш запрашивает из базы данных строки у которых метка выше чем сохранненая на данный момент в кэше. 
4. Последующий запрос от клиента к тому же предстиавлению с меткой n, где n>0, получает данные из кэша с метками вы n.
5. В случае если после некоторого промежутка времени запросов от клинта не поступает, обновление кэша останавливается. 

Для оценки качества работы механизма а также привильности его использования дргугими компонентами при нормальных условиях работы приложения мы ставим следующие критерии:

1. Большую часть вызовов должны составлять вызовы с n>0
2. Время выполения для вызовов с n>0 должно быть меньше, чем для аналогичных вызовов с n=0
3. 

В данной работе я хочу предложить рассмотреть использование ETW логирования и последующего статистического анализа и моделирования в качестве одной из альтернатив для анализа работы приложения. Для анализа я возьму стэк взаимодействия продукта с SQL базой данных. В данной работе я ставлю цель ответит на следующие вопросы:

1. Пременимость статистического анализа для изучения производительности работы приложений
2. Использование спонтанного обучения для прогнозирования работы приложения под нагрузкой



## 2. Данные

### 2.1 Выбор провайдера данных

Для решения поставленнной задачи мне необходимо получить набор струкрутрированных данных, которые должны содержать индетификатор действия, время выполнения, а также дополнительные праметры которые могут влиять не время выполнения.  В качестве поставищика данных мы можем использовать несколько вариантов. Рассмотрим их плюсы и минусы

| Тип поставщика          | Преимущества                                                 | Недостатки                                                   |
| ----------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Тесктовые логи          | Минимум усилий, Уже есть в продукте, Гибкость в использовании | Не структурированные данные, Накладные расходы IO, Большой размер файлов при длительном мониторинге, велика вероятность ошибок второго рода при приведении данных к структуре |
| SQL Perfomance Profiler | Встроенный профайлер, SQLMS, Данные предствлены в структурированном виде, Гибкость настройки представления, нет необходимости вносить изменения в исходный код | Медленная и не стабильная работа на больших объемах данных, Невоможность включить дополнительные параметры в набор данных, Плохо реализованный механизм фильтрации, Использование в полевых условиях требует установку SQLMS |
| SQL Peromance Monitor   | Большой набор инструментов для мониторинга, Настраеваемые представления данных, нет необходимости вносить изменения в исходный код | Необходима покупка лицензии, Невоможность включить дополнительные параметры в набор данных, Использование в полевых условиях требует установку SQLMS |
| ETW логирование         | Гибкость в использовании, Оптимальный мезанизм записи, Структурированный набор данных, возможность использовать для диагностики продакш сред у клиентов | Необходимо вносить изменения в продакш код, Неоходимо реализовывать собственный провайдер данных. Для использование необходимо довести до сведения команды разработчкиов о новом мехнизме |

Исходя из преведенной выше таблицы я остановлюсь на ETW логировании, так как данный мехнизм в наибольшей мере удовлетворяет нашим требованиям. 

### 2.2 ETW - логирование

ETW (Event Tracing for Windows) - мощный фраймворк встроенный в операционную систему. Сама Windows имеет тесную интерацию с ETW, включая данные о поведение системы вплоть до ядра: переключение контекстов, выделение памяти, создание процессов и много другое. Все это делает ETW отличным инструментом для сквозного анализа производительности многоуровневых систем. В отличии от тектового логирования фарймворк предоставлят структурированные данные, разработанные специально для автоматической обработки и анализа. [[1]]()

Важной отличительно способность ETW является прозводительность. Система использует механизм буферизации и вывода на уровне ядра, также для каждого процесса используется свой ассинхронный буфер, который в многопоточном режиме выполняет запись данных трассировки на диск.  Это позволяет крупным высоконагруженным приложениям  выполнять выполнять логирование с минимальным влиянием на производительность в целом. 

Второй важный момент - это возможность динамически включать и выключать трассировку без необходимосит перезупуска прилоджения или системы в целом. Это делает возможным использовать данный мезанизм в продакшн среде, что дает возможность тех. подержки анализировать поведение системы на конкретных клиентских кофигурация, непосредственно в продакшене. 

### 2.3 EventSource. Собственные события.

Одним из основных элементов фраймворка являются события, которые генерирует опереационная система или приложение. Windows поддерживает довольно большое колличество встроенных событий, позволяющих выполнять трассировку всех аспектов поведение системы. Для удобства разработчиков  в .Net начиная с версии 4.5 был добавлен класс EventSource[[2](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource?view=netcore-3.1)], механиз позволяющий приложению объявлять и генерировать собственные событие. 

Для целей моей работы, мне необходимо реализовать сбор данных взаимодействии нашего приложания с базой данных. Данные должны в себя включать: Индетификатор (имя хранимой процедуры или предствавления), время события, критерии запроса, индетификаторы начала и конца выполения запроса, сведния о состоянии базы данных. На основании этих требований я реализую собственный EventSource.
```csharp
[EventSource(Name = "DbInteractionEventSource")]
public class CDbInteractionEventSource : EventSource
{
        
	public static CDbInteractionEventSource Source = new CDbInteractionEventSource();

    public CDbInteractionEventSource() : base("DbInteractionEventSource")
    {

    }

    [Event((int)ECustomEvents.LoadDataStart, Message = "LoadDataStart", Level = EventLevel.Verbose, Keywords = CCustomKeywords.Reporter | CCustomKeywords.Database)]
    public void LoadDataStart(string viewName, string criteria, ulong usn, DateTime timestamp, string metrics = "")
    {
        WriteEvent((int)ECustomEvents.LoadDataStart, viewName, criteria, usn, timestamp, metrics);
    }

    [Event((int)ECustomEvents.LoadDataStop, Message = "LoadDataStop", Level = EventLevel.Verbose, Keywords = CCustomKeywords.Reporter | CCustomKeywords.Database)]
    public void LoadDataStop(string viewName, string criteria, ulong usn, DateTime timestamp, string metrics = "")
    {
    	WriteEvent((int)ECustomEvents.LoadDataStop, viewName, criteria, usn, timestamp, metrics);
    }

}
```

Пример использования в коде. Подробно парметры события в данной работе я разбирать не буду, так они довольно подробно описаны в документации MSDN Однако, стоить ометить ECustomEvents.LoadDataStart и ECustomEvents.LoadDataStop они омеют занчения 1 и 2 соответвенно. В этом случае мехенизм ETW будет связвать эти события и автоматически расчитывать время выполения. Также, код генерации будет выполнен только если выполняется коллект и подключен листенер, в противном случае код не вызывается. Этот факт как раз делает возмодным испольщовать такой подход к сбору данных в продакшн средах, без влияния на производительность прилодения в целом.


```csharp
using (SqlConnection sqlConnection = new SqlConnection(_dbConfiguration.ConnectionString))
{
	CDbInteractionEventSource.Source.LoadDataStart(ViewName, Criteria.GetKey(), usn, SManagedDateTime.Now, 	
                                                   _timeoutCalculator.SqlMetrics.ToString());
    try
	{
		//Execution logic here
	}
	catch (Exception ex)
	{
		//Exception handling here
	}

	CDbInteractionEventSource.Source.LoadDataStop(ViewName, Criteria.GetKey(), usn, SManagedDateTime.Now, 
                                              		_timeoutCalculator.SqlMetrics.ToString());
}       
```
### 2.4 Методология сбора данный

Для выполнения коллекта данных я использую PerfView [[3]]().  Запуск утилиты выполняется с командной строки ***PerfView.exe collect F:\PerfViewData\TestServer.etl /OnlyProviders=*DbInteractionEventSource*** В качестве парметров я указываю имя файла с результатом, а также даю иструкцию собирать данные только моего провайдера. 

Следующим шагом я выполняю тестирования с постепенным  увеличением нагрузки. Для больших продуктов с множестовом сценариев необходимо определиться что имеено будет тестироваться. В противном случае полученные данные будет двольно сложно интерпретировать. Хорошой отправной точкой для принятия решения является база суппортных кейсов. Так как имеено там можно найти реальные пролемы возникающие у клиентов и понять конфигруции который нужны для воспроизмедения и анализа. В этой работе я буду иследовать деградацию производительности пользовательского интерфейса в следствии возрастающей нагрузки на базу данных при работе Veeam Agent for Microsoft Windows в ключенной функцией Microsoft SQL Server Log Backup. 

![SQL_logs_hiw_vaw](EventLogsData/SQL_logs_hiw_vaw.png)

В качестве тестового стенда я использую:

1. VRBServer - 32 Cores 64 Gb RAM 
2. Репозиторий SOBR (узнать что там было)
3. 1500  виртуальных машин с SQL Server по 10 баз

Тест выполнялся в течении 24 часов с постепенно возрастающей нагрузкой на базу в следствии генерации новых данных при работе бэкапных джоб.

### 2.5 Результат

После прохождения всех необходимых нагрузочных  тестов я получаю  набор требуемых данных, который можно посмотреть с помощью PerfView. Для удобства дальнейшего анализа данные конвертируются в csv формат

![perf](EventLogsData/perf.png)

## 3. Обработка данных. Визуальный анализ

### 3.1 Очистка данных

```python
rawData = pd.read_csv('data/SqlMetric_prepared.csv')
rawData.head()
```

Полученные [данные](https://github.com/tonnyeremin/Software-Perfomance/blob/master/SqlMetrics/data/SqlMetric_prepared.csv),  уже хорошо структурированы и требуют минимальной очистки. В качестве первого шага я удаляю строки не представляющие интереса для данного исследовани: ActivityID, ProcessID, criteria, EventName. Следующий этап - обработка пропущенных значений. Принимая во внимание, что значение DURATION_MSEC, записывается только на во втором событии из пары а сама пара событий идетнична, я могу удалить строки с пропущенными занчениями. На выходе я получаю 173974 строки.

```python
rawData.isnull().sum()

Time MSec             0
DURATION_MSEC    173975
metrics               0
timestamp             0
usn                   0
viewName              0
dtype: int64

rawData.dropna(inplace=True)
print(rawData.isnull().sum())
print('Dataset shape: {}'.format(rawData.shape))
```

На следующем шаге, я выполняю преобразование данных в необходимый для обработки вид. Строковые значения из колонки **metrics**  

```
Table_1:47 Table_2:476 Table_3:199 Table_4:56
```

Я преобразую в отдельные столбцы **Table_1 Table_2  Table_3  Table_4**  соответвенно. 

```python
rawData['db_state'] = rawData['metrics'].apply(lambda x: x.split(' '))
rawData.drop(['metrics'], axis=1, inplace=True)
print('Dataset shape: {}'.format(rawData.shape))
row = rawData.iloc[0,5]
print('Metrics: {}'.format(row))

dic = {}

for st in row:
    splitted = st.split(':')
    key = splitted[0] 
    dic[key] = [] 
    
print('Parsing sql metrics')
for index, row in rawData.iterrows():
    metrics_row = row['db_state']
    for i in range(0,4):
        st = metrics_row[i]
        splitted = st.split(':')
        key = 'Table_{}'.format(i+1)
        val = np.NaN   
        if len(splitted)>1:
            val = int(splitted[1])
        
        dic[key].append(val)
        

print('Adding new metrics collumns')     
for key in dic.keys():
    rawData[key] = dic[key]

print('Drop db_state column')
rawData.drop(['db_state'], axis=1, inplace=True)
    
print('Parsing sql metrics finnised')
print('Dataset shape: {}'.format(rawData.shape))
```

Завершающем этапом я еще раз проверю набор данных на пропущеные значения, выполняю переименование колонок, преобразую строковые значения в числовой формат. В результате я получаю следующий набор данных. 

|      | timestamp | duration |    viewName | Table_1 | Table_2 | Table_3 | Table_4 | is_cold_start |
| ---: | --------: | -------: | ----------: | ------: | ------: | ------: | ------: | ------------: |
|    1 |  2621.028 |  102.572 | Procedure_0 |    47.0 |   476.0 |   199.0 |    56.0 |          True |
|    3 |  2700.351 |   79.245 | Procedure_1 |    47.0 |   476.0 |   199.0 |    56.0 |          True |
|    5 |  2701.448 |    1.073 | Procedure_2 |    47.0 |   476.0 |   199.0 |    56.0 |          True |
|    7 |  6288.764 | 3587.280 | Procedure_3 |    47.0 |   476.0 |   199.0 |    56.0 |          True |
|    9 |  6386.315 |   97.403 | Procedure_4 |    47.0 |   476.0 |   199.0 |    56.0 |         False |

Подробный код этого и все последующих шагов можно посмотреть на [GitHib](https://github.com/tonnyeremin/Software-Perfomance/blob/master/SqlMetrics/Evangelist_Perf_Processing.ipynb)

### 3.2 Описание данных. Ститистический и визуальный анализ

Для поверхностиного анализа нашего набора, определение общей тенденции, десиперсии и придельных значенеий, поcмотрим на описательные статистические данные:

|       |    timestamp |      duration |  Table_1 |       Table_2 |       Table_3 |  Table_4 |        second |
| ----: | -----------: | ------------: | -------: | ------------: | ------------: | -------: | ------------: |
| count | 1.691300e+05 | 169130.000000 | 169130.0 | 169130.000000 | 169130.000000 | 169130.0 | 169130.000000 |
|  mean | 7.477735e+07 |    193.602204 |     47.0 |   2575.708585 |    543.799947 |     56.0 |  74777.346065 |
|   std | 4.097056e+07 |   1734.437014 |      0.0 |    938.529156 |     85.067045 |      0.0 |  40970.560275 |
|   min | 2.621028e+03 |      0.561000 |     47.0 |    476.000000 |    196.000000 |     56.0 |      3.000000 |
|   25% | 4.076446e+07 |     10.921000 |     47.0 |   1917.000000 |    555.000000 |     56.0 |  40764.000000 |
|   50% | 7.403702e+07 |     64.465000 |     47.0 |   2664.000000 |    559.000000 |     56.0 |  74037.000000 |
|   75% | 1.100676e+08 |    121.580250 |     47.0 |   3360.000000 |    595.000000 |     56.0 | 110068.000000 |
|   max | 1.461257e+08 | 163248.610000 |     47.0 |   4075.000000 |    596.000000 |     56.0 | 146126.000000 |

Наибольший интерес для нас здесь представляет значения  параметров **duration** , **Table_1**, **Table_2**, **Table_3**, **Table_4**. Из таблицы мы видим что наибольшая величина дисперсии у параметра **duration**, а также большое различие перцентилей и максимального значения для этого параметра. Это говорит о неравномерности распеределения данных, или об аномалиях в наборе данных. **Table_1**, **Table_4** имеют нулевую дисперсию, следовательно для нашего ислодования мы можем принебречь этими заначениями. Исходя из этого в нашей дальнейшей работе мы будет исследовать зависимость занчения  **duration** от **Table_2**, **Table_3**.

При сборе данных мы ввели значение **is_cold_start**. Это значение = 1 в случае когда запрос из представления происходит с забором всех данных обычно это первый запрос для помещения данных в кэш приложения, заначение = 0, в случае запроса только обновленных данных, выполняеться для обновления кэша. Рассмотрим общее число запросов, а также процентное отношение данных полученных для инициализации кэша, к запросам выполенем для его обновления. 

```python
normal_execution =  data.loc[data['is_cold_start']==False, :]
cold_execution = data.loc[data['is_cold_start']==True, :]
cold_percentage =len(cold_execution)*100/len(data)
normal_percentage = 100 - cold_percentage Hf
print ("Total executions {} Normal execution {}({:,.2f}% from total, Cold execution {}({:,.2f}% form total))".format(len(data), len(normal_execution),normal_percentage,len(cold_execution),cold_percentage))
```

В результате, мы получили, общеее число вызовов **169130** из них инициализация данных **109069 (64.49%)** и обновления **60061 (35.51%)**.  Эти результаты могут свидетельствовать о неэфективном использовании механизма кэширования приложением.

Разделим наш набор данных по признаку **is_cold_start**. Рассмотрим эти два набора 

## 4. Построение модели

## 5. Выводы

## 6. Следующие шаги

## 7. Использованная литература

1. [Announcing TraceProcessor Preview 0.1.0. David Matson](https://blogs.windows.com/windowsdeveloper/2019/05/09/announcing-traceprocessor-preview-0-1-0/)
2. [Event Source class](https://docs.microsoft.com/en-us/dotnet/api/system.diagnostics.tracing.eventsource?view=netcore-3.1)
3. [PerfView on GitHub](https://github.com/microsoft/perfview)
4. J. Paparrizos & L. Gravano. k-Shape: Efficient and Accurate Clustering of Time Series. SIGMOD 2015. pp. 1855-1870.